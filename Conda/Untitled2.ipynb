{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02b3ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# API-Anfrage durchführen\n",
    "url = \"https://api.polygon.io/v2/aggs/ticker/AAPL/range/1/day/2022-06-17/2023-06-17\"\n",
    "params = {\n",
    "    \"adjusted\": \"true\",\n",
    "    \"sort\": \"asc\",\n",
    "    \"limit\": 120,\n",
    "    \"apiKey\": \"AtE7dRJG_TP0fPRBCnu1gGpNMe580JCY\"\n",
    "}\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "# Datenverarbeitung\n",
    "results = data['results']\n",
    "df = pd.DataFrame(results)\n",
    "df['timestamp'] = pd.to_datetime(df['t'], unit='ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "313ed5f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "('42S01', \"[42S01] [Microsoft][ODBC SQL Server Driver][SQL Server]There is already an object named 'stock_data' in the database. (2714) (SQLExecDirectW)\")",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HERBYH~1\\AppData\\Local\\Temp/ipykernel_15576/2984009395.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[0mtable_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"stock_data\"\u001b[0m  \u001b[1;31m# Name der Zieltabelle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mcreate_table_query\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"CREATE TABLE {table_name} (timestamp datetime, o decimal(18, 8), h decimal(18, 8), l decimal(18, 8), c decimal(18, 8), v decimal(18, 8))\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_table_query\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# Daten in die Tabelle einfügen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mProgrammingError\u001b[0m: ('42S01', \"[42S01] [Microsoft][ODBC SQL Server Driver][SQL Server]There is already an object named 'stock_data' in the database. (2714) (SQLExecDirectW)\")"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Verbindungsstring\n",
    "conn_str = (\n",
    "    r'Driver=SQL Server;'\n",
    "    r'Server=.\\SQLEXPRESS;'\n",
    "    r'Database=studienprojekt;'\n",
    "    r'Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "# Verbindung zur Datenbank herstellen\n",
    "cnxn = pyodbc.connect(conn_str)\n",
    "cursor = cnxn.cursor()\n",
    "\n",
    "# API-Anfrage durchführen\n",
    "url = \"https://api.polygon.io/v2/aggs/ticker/AAPL/range/1/day/2022-06-17/2023-06-17\"\n",
    "params = {\n",
    "    \"adjusted\": \"true\",\n",
    "    \"sort\": \"asc\",\n",
    "    \"limit\": 500,\n",
    "    \"apiKey\": \"AtE7dRJG_TP0fPRBCnu1gGpNMe580JCY\"\n",
    "}\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "# Datenverarbeitung\n",
    "results = data['results']\n",
    "df = pd.DataFrame(results)\n",
    "df['timestamp'] = pd.to_datetime(df['t'], unit='ms')\n",
    "\n",
    "# Tabelle erstellen\n",
    "table_name = \"stock_data\"  # Name der Zieltabelle\n",
    "create_table_query = f\"CREATE TABLE {table_name} (timestamp datetime, o decimal(18, 8), h decimal(18, 8), l decimal(18, 8), c decimal(18, 8), v decimal(18, 8))\"\n",
    "cursor.execute(create_table_query)\n",
    "\n",
    "# Daten in die Tabelle einfügen\n",
    "for _, row in df.iterrows():\n",
    "    insert_query = f\"INSERT INTO {table_name} (timestamp, o, h, l, c, v) VALUES (?, ?, ?, ?, ?, ?)\"\n",
    "    cursor.execute(insert_query, row['timestamp'], row['o'], row['h'], row['l'], row['c'], row['v'])\n",
    "\n",
    "# Änderungen in der Datenbank übernehmen\n",
    "cnxn.commit()\n",
    "\n",
    "print(\"Daten wurden erfolgreich in die SQL-Tabelle eingefügt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5950a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsarray\n",
    "c*number\n",
    "\n",
    "The close price for the symbol in the given time period.\n",
    "h*number\n",
    "\n",
    "The highest price for the symbol in the given time period.\n",
    "l*number\n",
    "\n",
    "The lowest price for the symbol in the given time period.\n",
    "ninteger\n",
    "\n",
    "The number of transactions in the aggregate window.\n",
    "o*number\n",
    "\n",
    "The open price for the symbol in the given time period.\n",
    "otcboolean\n",
    "\n",
    "Whether or not this aggregate is for an OTC ticker. This field will be left off if false.\n",
    "t*integer\n",
    "\n",
    "The Unix Msec timestamp for the start of the aggregate window.\n",
    "v*number\n",
    "\n",
    "The trading volume of the symbol in the given time period.\n",
    "vwnumber\n",
    "\n",
    "The volume weighted average price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec5ff827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Tabelle enthält bereits Daten ab dem angegebenen Startdatum. Es wurden keine weiteren Daten hinzugefügt.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Verbindungsstring\n",
    "conn_str = (\n",
    "    r'Driver=SQL Server;'\n",
    "    r'Server=.\\SQLEXPRESS;'\n",
    "    r'Database=studienprojekt;'\n",
    "    r'Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "# Verbindung zur Datenbank herstellen\n",
    "cnxn = pyodbc.connect(conn_str)\n",
    "cursor = cnxn.cursor()\n",
    "\n",
    "# Tabelle prüfen\n",
    "table_name = \"stock_data\"  # Name der Zieltabelle\n",
    "start_date = \"2022-06-17\"  # Startdatum, ab dem Daten überprüft werden sollen\n",
    "check_data_query = f\"SELECT MAX(timestamp) FROM {table_name}\"\n",
    "cursor.execute(check_data_query)\n",
    "row = cursor.fetchone()\n",
    "max_timestamp = row[0]\n",
    "\n",
    "# Daten nur einfügen, wenn keine vorhanden sind\n",
    "if max_timestamp is None or max_timestamp.date() < pd.to_datetime(start_date).date():\n",
    "    # API-Anfrage durchführen\n",
    "    url = \"https://api.polygon.io/v2/aggs/ticker/AAPL/range/1/day/2022-06-17/2023-06-17\"\n",
    "    params = {\n",
    "        \"adjusted\": \"true\",\n",
    "        \"sort\": \"asc\",\n",
    "        \"limit\": 500,\n",
    "        \"apiKey\": \"AtE7dRJG_TP0fPRBCnu1gGpNMe580JCY\"\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    data = response.json()\n",
    "\n",
    "    # Datenverarbeitung\n",
    "    results = data['results']\n",
    "    df = pd.DataFrame(results)\n",
    "    df['timestamp'] = pd.to_datetime(df['t'], unit='ms')\n",
    "\n",
    "    # Tabelle erstellen\n",
    "    create_table_query = f\"CREATE TABLE {table_name} (timestamp datetime, o decimal(18, 8), h decimal(18, 8), l decimal(18, 8), c decimal(18, 8), v decimal(18, 8))\"\n",
    "    cursor.execute(create_table_query)\n",
    "\n",
    "    # Daten in die Tabelle einfügen\n",
    "    for _, row in df.iterrows():\n",
    "        insert_query = f\"INSERT INTO {table_name} (timestamp, o, h, l, c, v) VALUES (?, ?, ?, ?, ?, ?)\"\n",
    "        cursor.execute(insert_query, row['timestamp'], row['o'], row['h'], row['l'], row['c'], row['v'])\n",
    "\n",
    "    # Änderungen in der Datenbank übernehmen\n",
    "    cnxn.commit()\n",
    "\n",
    "    print(\"Daten wurden erfolgreich in die SQL-Tabelle eingefügt.\")\n",
    "else:\n",
    "    print(\"Die Tabelle enthält bereits Daten ab dem angegebenen Startdatum. Es wurden keine weiteren Daten hinzugefügt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4888aecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten wurden erfolgreich in die SQL-Tabelle eingefügt.\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Verbindungsstring\n",
    "conn_str = (\n",
    "    r'Driver=SQL Server;'\n",
    "    r'Server=.\\SQLEXPRESS;'\n",
    "    r'Database=studienprojekt;'\n",
    "    r'Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "# Verbindung zur Datenbank herstellen\n",
    "cnxn = pyodbc.connect(conn_str)\n",
    "cursor = cnxn.cursor()\n",
    "\n",
    "# Tabelle prüfen\n",
    "table_name = \"stock_data\"  # Name der Zieltabelle\n",
    "start_date = \"2022-06-17\"  # Startdatum, ab dem Daten überprüft werden sollen\n",
    "\n",
    "# Daten aus der Tabelle in einen DataFrame laden\n",
    "select_query = f\"SELECT * FROM {table_name}\"\n",
    "df_existing_data = pd.read_sql(select_query, cnxn)\n",
    "\n",
    "# API-Anfrage durchführen\n",
    "url = \"https://api.polygon.io/v2/aggs/ticker/AAPL/range/1/day/2022-06-17/2023-06-17\"\n",
    "params = {\n",
    "    \"adjusted\": \"true\",\n",
    "    \"sort\": \"asc\",\n",
    "    \"limit\": 500,\n",
    "    \"apiKey\": \"AtE7dRJG_TP0fPRBCnu1gGpNMe580JCY\"\n",
    "}\n",
    "response = requests.get(url, params=params)\n",
    "data = response.json()\n",
    "\n",
    "# Datenverarbeitung\n",
    "results = data['results']\n",
    "df_new_data = pd.DataFrame(results)\n",
    "df_new_data['timestamp'] = pd.to_datetime(df_new_data['t'], unit='ms')\n",
    "\n",
    "# Daten nur einfügen, wenn sie noch nicht vorhanden sind\n",
    "for _, row in df_new_data.iterrows():\n",
    "    timestamp = row['timestamp']\n",
    "    existing_row = df_existing_data[df_existing_data['timestamp'] == timestamp]\n",
    "    if existing_row.empty:\n",
    "        # Daten in die Tabelle einfügen\n",
    "        insert_query = f\"INSERT INTO {table_name} (timestamp, o, h, l, c, v) VALUES (?, ?, ?, ?, ?, ?)\"\n",
    "        cursor.execute(insert_query, timestamp, row['o'], row['h'], row['l'], row['c'], row['v'])\n",
    "\n",
    "# Änderungen in der Datenbank übernehmen\n",
    "cnxn.commit()\n",
    "\n",
    "print(\"Daten wurden erfolgreich in die SQL-Tabelle eingefügt.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd139034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
