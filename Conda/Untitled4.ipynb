{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57314065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HerbyHerb\\AppData\\Local\\Temp\\ipykernel_12424\\417937183.py:19: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  data = pd.read_sql(query, connection)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 7s 25ms/step - loss: 0.0793\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.0189\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0163\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0136\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0123\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0112\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.0101\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0093\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0086\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.0083\n",
      "1/1 [==============================] - 1s 845ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1, 1), indices imply (30, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m predictions_index \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mdate_range(start\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m31\u001b[39m], periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# DataFrame für die Vorhersagen erstellen\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m predictions_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_month_predictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Plot der historischen Daten und Vorhersagen\u001b[39;00m\n\u001b[0;32m     69\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m], data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHistorical Data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf_new\\lib\\site-packages\\pandas\\core\\frame.py:722\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    712\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    713\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    714\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    719\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[0;32m    720\u001b[0m         )\n\u001b[0;32m    721\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 722\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    724\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    727\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    728\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf_new\\lib\\site-packages\\pandas\\core\\internals\\construction.py:349\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    345\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[0;32m    346\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[0;32m    347\u001b[0m )\n\u001b[1;32m--> 349\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    353\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf_new\\lib\\site-packages\\pandas\\core\\internals\\construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (1, 1), indices imply (30, 1)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# Verbindungsstring zur MS SQL-Datenbank\n",
    "conn_str = (\n",
    "    r'Driver={SQL Server};'\n",
    "    r'Server=.\\SQLEXPRESS;'\n",
    "    r'Database=studienprojekt;'\n",
    "    r'Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "# Verbindung zur MS SQL-Datenbank herstellen und Daten abrufen\n",
    "connection = pyodbc.connect(conn_str)\n",
    "query = \"SELECT timestamp, o, c, h, l FROM stock_data ORDER BY timestamp\"\n",
    "data = pd.read_sql(query, connection)\n",
    "\n",
    "# Daten vorbereiten\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data[['c']])\n",
    "\n",
    "# Aufteilung der Daten in Trainings- und Testdaten\n",
    "train_data = scaled_data[:-30]\n",
    "test_data = scaled_data[-30:]\n",
    "\n",
    "# Funktion zum Erstellen der Trainingsdaten für das LSTM-Modell\n",
    "def create_lstm_dataset(dataset, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(dataset)-look_back):\n",
    "        X.append(dataset[i:i+look_back, 0])\n",
    "        Y.append(dataset[i+look_back, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# Trainingsdaten erstellen\n",
    "look_back = 30\n",
    "train_X, train_Y = create_lstm_dataset(train_data, look_back)\n",
    "\n",
    "# Daten für das LSTM-Modell reshape\n",
    "train_X = np.reshape(train_X, (train_X.shape[0], train_X.shape[1], 1))\n",
    "\n",
    "# LSTM-Modell erstellen\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=50, return_sequences=True, input_shape=(look_back, 1)))\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dense(units=1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Modell trainieren\n",
    "model.fit(train_X, train_Y, epochs=10, batch_size=32)\n",
    "\n",
    "# Vorhersage für den nächsten Monat\n",
    "test_X = test_data\n",
    "test_X = np.reshape(test_X, (1, look_back, 1))\n",
    "next_month_predictions = model.predict(test_X)\n",
    "\n",
    "# Denormalisierung der Daten\n",
    "next_month_predictions = scaler.inverse_transform(next_month_predictions)\n",
    "\n",
    "# Index für die Vorhersage erstellen\n",
    "predictions_index = pd.date_range(start=data['timestamp'].iloc[-31], periods=30, freq='D')\n",
    "\n",
    "# DataFrame für die Vorhersagen erstellen\n",
    "predictions_df = pd.DataFrame(next_month_predictions, index=predictions_index, columns=['Prediction'])\n",
    "\n",
    "# Plot der historischen Daten und Vorhersagen\n",
    "plt.plot(data['timestamp'], data['c'], label='Historical Data')\n",
    "plt.plot(predictions_df.index, predictions_df['Prediction'], label='Next Month Predictions')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Closing Price')\n",
    "plt.title('Stock Price Prediction')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d4e5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
