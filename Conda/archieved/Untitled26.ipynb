{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3856e4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date        open        high         low       close    volume type  \\\n",
      "246 2023-06-26  186.830002  188.050003  185.229996  185.270004  48088700  ACT   \n",
      "247 2023-06-27  185.889999  188.389999  185.669998  188.059998  50730800  ACT   \n",
      "248 2023-06-28  187.929993  189.899994  187.600006  189.250000  51216800  ACT   \n",
      "249 2023-06-29  189.080002  190.070007  188.940002  189.589996  46347300  ACT   \n",
      "250 2023-06-30  191.630005  194.479996  191.259995  193.970001  85069600  ACT   \n",
      "\n",
      "    company  \n",
      "246    AAPL  \n",
      "247    AAPL  \n",
      "248    AAPL  \n",
      "249    AAPL  \n",
      "250    AAPL  \n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import datetime\n",
    "from datetime import date, timedelta\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Verbindungsstring\n",
    "conn_str = (\n",
    "    r'Driver=SQL Server;'\n",
    "    r'Server=.\\SQLEXPRESS;'\n",
    "    r'Database=studienprojekt;'\n",
    "    r'Trusted_Connection=yes;'\n",
    ")\n",
    "\n",
    "# Verbindung zur Datenbank herstellen\n",
    "cnxn = pyodbc.connect(conn_str)\n",
    "\n",
    "# SQLAlchemy connectable erstellen\n",
    "engine = create_engine('mssql+pyodbc://', creator=lambda: cnxn)\n",
    "\n",
    "# Tabelle prüfen\n",
    "table_name = \"stock_data\"  # Name der Zieltabelle\n",
    "start_date = \"2022-07-01\"  # Startdatum, ab dem Daten überprüft werden sollen\n",
    "end_date = \"2023-07-01\"  # Enddatum, bis zu dem Daten überprüft werden sollen\n",
    "\n",
    "# Daten aus der Tabelle in einen DataFrame laden\n",
    "select_query = f\"SELECT * FROM {table_name} WHERE date >= ? AND date <= ?\"\n",
    "data = pd.read_sql(select_query, con=engine, params=(start_date, end_date))\n",
    "\n",
    "# added\n",
    "data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "data = data[[\"date\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"type\", \"company\"]]\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Verbindung schließen\n",
    "cnxn.close()\n",
    "\n",
    "# DataFrame anzeigen\n",
    "print(data.tail())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "307c7539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                  close   No. Observations:                  251\n",
      "Model:                 ARIMA(5, 1, 2)   Log Likelihood                -604.830\n",
      "Date:                Fri, 07 Jul 2023   AIC                           1225.659\n",
      "Time:                        18:11:13   BIC                           1253.831\n",
      "Sample:                             0   HQIC                          1236.998\n",
      "                                - 251                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1         -0.1212      0.242     -0.501      0.616      -0.595       0.353\n",
      "ar.L2         -0.6587      0.183     -3.598      0.000      -1.017      -0.300\n",
      "ar.L3         -0.0242      0.088     -0.275      0.783      -0.196       0.148\n",
      "ar.L4         -0.1672      0.081     -2.052      0.040      -0.327      -0.007\n",
      "ar.L5          0.1051      0.079      1.332      0.183      -0.050       0.260\n",
      "ma.L1          0.0995      0.240      0.414      0.679      -0.371       0.570\n",
      "ma.L2          0.5929      0.170      3.483      0.000       0.259       0.926\n",
      "sigma2         7.3871      0.581     12.705      0.000       6.248       8.527\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.01   Jarque-Bera (JB):                47.36\n",
      "Prob(Q):                              0.94   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.46   Skew:                             0.37\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                         5.00\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n",
      "0        0.000000\n",
      "1      138.929960\n",
      "2      141.480839\n",
      "3      142.668123\n",
      "4      146.122337\n",
      "          ...    \n",
      "246    186.497437\n",
      "247    185.197519\n",
      "248    187.596649\n",
      "249    189.536626\n",
      "250    189.885223\n",
      "Name: predicted_mean, Length: 251, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HerbyHerb\\.conda\\envs\\tf_new\\lib\\site-packages\\statsmodels\\base\\model.py:604: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     SARIMAX Results                                      \n",
      "==========================================================================================\n",
      "Dep. Variable:                              close   No. Observations:                  251\n",
      "Model:             SARIMAX(5, 1, 2)x(5, 1, 2, 12)   Log Likelihood                -591.181\n",
      "Date:                            Fri, 07 Jul 2023   AIC                           1212.362\n",
      "Time:                                    18:11:36   BIC                           1264.446\n",
      "Sample:                                         0   HQIC                          1233.353\n",
      "                                            - 251                                         \n",
      "Covariance Type:                              opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1          0.6296      0.320      1.964      0.049       0.001       1.258\n",
      "ar.L2          0.0679      0.332      0.204      0.838      -0.583       0.719\n",
      "ar.L3          0.0728      0.082      0.883      0.377      -0.089       0.234\n",
      "ar.L4         -0.1072      0.093     -1.158      0.247      -0.289       0.074\n",
      "ar.L5          0.2293      0.081      2.831      0.005       0.071       0.388\n",
      "ma.L1         -0.6613      0.318     -2.079      0.038      -1.285      -0.038\n",
      "ma.L2         -0.1529      0.327     -0.468      0.640      -0.794       0.488\n",
      "ar.S.L12      -0.5972      0.752     -0.794      0.427      -2.071       0.877\n",
      "ar.S.L24      -0.2215      0.145     -1.523      0.128      -0.506       0.063\n",
      "ar.S.L36      -0.1489      0.169     -0.883      0.377      -0.480       0.182\n",
      "ar.S.L48      -0.0236      0.148     -0.159      0.873      -0.314       0.267\n",
      "ar.S.L60      -0.0733      0.116     -0.629      0.529      -0.301       0.155\n",
      "ma.S.L12      -0.5008      0.828     -0.605      0.545      -2.125       1.123\n",
      "ma.S.L24      -0.4591      0.802     -0.573      0.567      -2.030       1.112\n",
      "sigma2         7.1555      2.452      2.919      0.004       2.350      11.961\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.00   Jarque-Bera (JB):                66.80\n",
      "Prob(Q):                              0.98   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.40   Skew:                             0.59\n",
      "Prob(H) (two-sided):                  0.00   Kurtosis:                         5.32\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array length 30 does not match index length 31",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m dates \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mdate_range(start\u001b[38;5;241m=\u001b[39mdata[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimedelta(days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# DataFrame für die Vorhersagen erstellen\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m predictions_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclose\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Vorhersagen zum ursprünglichen DataFrame hinzufügen\u001b[39;00m\n\u001b[0;32m     35\u001b[0m data_f \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([data, predictions])\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf_new\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf_new\\lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf_new\\lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf_new\\lib\\site-packages\\pandas\\core\\internals\\construction.py:680\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lengths[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m    676\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    677\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray length \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlengths[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    678\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    679\u001b[0m         )\n\u001b[1;32m--> 680\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    682\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(lengths[\u001b[38;5;241m0\u001b[39m])\n",
      "\u001b[1;31mValueError\u001b[0m: array length 30 does not match index length 31"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "result = seasonal_decompose(data[\"close\"], model='multiplicative', period=30)\n",
    "\n",
    "\n",
    "p, d, q = 5, 1, 2\n",
    "\n",
    "model = ARIMA(data[\"close\"], order=(p,d,q))\n",
    "fitted = model.fit()\n",
    "\n",
    "print(fitted.summary())\n",
    "\n",
    "predictions = fitted.predict()\n",
    "print(predictions)\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "model=sm.tsa.statespace.SARIMAX(data['close'],\n",
    "                                order=(p, d, q),\n",
    "                                seasonal_order=(p, d, q, 12))\n",
    "model=model.fit()\n",
    "print(model.summary())\n",
    "\n",
    "# Vorhersagen erstellen\n",
    "start_point = len(data)\n",
    "end_point = start_point + 30\n",
    "predictions = model.predict(start_point, end_point)\n",
    "\n",
    "# Erstelle Datumsindex für die Vorhersagen\n",
    "dates = pd.date_range(start=data[\"date\"].iloc[-1] + pd.Timedelta(days=1), periods=30)\n",
    "\n",
    "# DataFrame für die Vorhersagen erstellen\n",
    "predictions_df = pd.DataFrame({'date': dates, 'close': predictions})\n",
    "\n",
    "# Vorhersagen zum ursprünglichen DataFrame hinzufügen\n",
    "data_f = pd.concat([data, predictions])\n",
    "\n",
    "# DataFrame anzeigen\n",
    "print(data_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549395c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2d38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "924203e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date        open        high         low       close      volume  \\\n",
      "246 2023-06-26  186.830002  188.050003  185.229996  185.270004  48088700.0   \n",
      "247 2023-06-27  185.889999  188.389999  185.669998  188.059998  50730800.0   \n",
      "248 2023-06-28  187.929993  189.899994  187.600006  189.250000  51216800.0   \n",
      "249 2023-06-29  189.080002  190.070007  188.940002  189.589996  46347300.0   \n",
      "250 2023-06-30  191.630005  194.479996  191.259995  193.970001  85069600.0   \n",
      "\n",
      "    type company  \n",
      "246  ACT    AAPL  \n",
      "247  ACT    AAPL  \n",
      "248  ACT    AAPL  \n",
      "249  ACT    AAPL  \n",
      "250  ACT    AAPL  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HerbyHerb\\AppData\\Local\\Temp\\ipykernel_17776\\1594748036.py:12: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  pred_df[col] = pd.np.nan\n",
      "C:\\Users\\HerbyHerb\\AppData\\Local\\Temp\\ipykernel_17776\\1594748036.py:12: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  pred_df[col] = pd.np.nan\n",
      "C:\\Users\\HerbyHerb\\AppData\\Local\\Temp\\ipykernel_17776\\1594748036.py:12: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  pred_df[col] = pd.np.nan\n",
      "C:\\Users\\HerbyHerb\\AppData\\Local\\Temp\\ipykernel_17776\\1594748036.py:12: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  pred_df[col] = pd.np.nan\n",
      "C:\\Users\\HerbyHerb\\AppData\\Local\\Temp\\ipykernel_17776\\1594748036.py:12: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  pred_df[col] = pd.np.nan\n",
      "C:\\Users\\HerbyHerb\\AppData\\Local\\Temp\\ipykernel_17776\\1594748036.py:12: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead.\n",
      "  pred_df[col] = pd.np.nan\n"
     ]
    }
   ],
   "source": [
    "# Vorhersagen in ein neues DataFrame umwandeln\n",
    "pred_df = pd.DataFrame(predictions, columns=[\"close\"])\n",
    "\n",
    "# Datumsspalte erstellen, die auf den Tag nach dem letzten Datum in den vorhandenen Daten folgt\n",
    "pred_df[\"date\"] = pd.date_range(start=data[\"date\"].iloc[-1] + timedelta(days=1), periods=len(pred_df), freq='D')\n",
    "\n",
    "# Die Reihenfolge der Spalten anpassen\n",
    "pred_df = pred_df[[\"date\", \"close\"]]\n",
    "\n",
    "# Die anderen Spalten in pred_df mit NaN-Werten füllen\n",
    "for col in [\"open\", \"high\", \"low\", \"volume\", \"type\", \"company\"]:\n",
    "    pred_df[col] = pd.np.nan\n",
    "\n",
    "# Das Vorhersage-DataFrame an das ursprüngliche DataFrame anhängen\n",
    "new_df = pd.concat([data, pred_df])\n",
    "\n",
    "# DataFrame anzeigen\n",
    "print(new_df.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56e98edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date        open        high         low       close    volume type  \\\n",
      "0   2022-07-01  136.039993  139.039993  135.660004  138.929993  71051600  ACT   \n",
      "1   2022-07-05  137.770004  141.610001  136.929993  141.559998  73353800  ACT   \n",
      "2   2022-07-06  141.350006  144.119995  141.080002  142.919998  74064300  ACT   \n",
      "3   2022-07-07  143.289993  146.550003  143.279999  146.350006  66253700  ACT   \n",
      "4   2022-07-08  145.259995  147.550003  145.000000  147.039993  64547800  ACT   \n",
      "..         ...         ...         ...         ...         ...       ...  ...   \n",
      "246 2023-06-26  186.830002  188.050003  185.229996  185.270004  48088700  ACT   \n",
      "247 2023-06-27  185.889999  188.389999  185.669998  188.059998  50730800  ACT   \n",
      "248 2023-06-28  187.929993  189.899994  187.600006  189.250000  51216800  ACT   \n",
      "249 2023-06-29  189.080002  190.070007  188.940002  189.589996  46347300  ACT   \n",
      "250 2023-06-30  191.630005  194.479996  191.259995  193.970001  85069600  ACT   \n",
      "\n",
      "    company  \n",
      "0      AAPL  \n",
      "1      AAPL  \n",
      "2      AAPL  \n",
      "3      AAPL  \n",
      "4      AAPL  \n",
      "..      ...  \n",
      "246    AAPL  \n",
      "247    AAPL  \n",
      "248    AAPL  \n",
      "249    AAPL  \n",
      "250    AAPL  \n",
      "\n",
      "[251 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "244cd75f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpredictions_df\u001b[49m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b602473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
